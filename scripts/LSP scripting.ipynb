{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: '/home/ubuntu/datasets/lsp/CO_LSP_train2016.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-d114c3d5953b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mLSP_IMAGES_SERVER_FOLDER\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/static/images/lsp/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mLSP_ANNOTATION_FILE\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0m_lsp_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: '/home/ubuntu/datasets/lsp/CO_LSP_train2016.json'"
     ]
    }
   ],
   "source": [
    "LSP_ANNOTATION_FILE = '/home/ubuntu/datasets/lsp/CO_LSP_train2016.json'\n",
    "LSP_IMAGES_FOLDER = 'http://vision.caltech.edu/~mronchi/data/LSP/images/'\n",
    "LSP_IMAGES_SERVER_FOLDER = '/static/images/lsp/'\n",
    "\n",
    "with open( LSP_ANNOTATION_FILE ) as f:\n",
    "    _lsp_dataset = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSP mongodb scripting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import sys\n",
    "from pymongo import MongoClient\n",
    "_mongo_client = MongoClient()\n",
    "\n",
    "_mongo_db = _mongo_client.cocoa_depth_lsp\n",
    "\n",
    "_mongo_coll_1 = _mongo_db.depth_amt_gui_data\n",
    "_mongo_coll_2 = _mongo_db.keypoint_labels\n",
    "_mongo_coll_3 = _mongo_db.depth_hit_id2lsp_subj_id\n",
    "_mongo_coll_4 = _mongo_db.lsp_subj_id2depth_hit_id\n",
    "\n",
    "_mongo_coll_5 = _mongo_db.depth_amt_gui_workers\n",
    "_mongo_coll_6 = _mongo_db.depth_amt_gui_blocked_workers\n",
    "\n",
    "_mongo_coll_7 = _mongo_db.depth_amt_gui_trials_results\n",
    "_mongo_coll_8 = _mongo_db.depth_amt_gui_hits_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cursor = _mongo_coll_8.find({})\n",
    "for document in cursor:\n",
    "    # print document\n",
    "    if document['_hit_comment'] != \"\":\n",
    "        # print document['_hit_id']\n",
    "        print document['_hit_comment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "worker_ids = set([i['_worker_id'] for i in _mongo_coll_8.find()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Oisin, AA1R5HDNQYVCC, 20 hits\n",
    "# Matteo, ADU86DR9LRC0G, 16 hits\n",
    "# Robert, A27877Z7ZEGJPX, 18 hits\n",
    "# Matteo 2, A1GM8ZHDSD19ZQ, 4 hits ## he has two worker ids for some reason\n",
    "hits = [i for i in _mongo_coll_8.find({'_worker_id':'A27877Z7ZEGJPX'})]\n",
    "hit_ids = sorted([h['_hit_id'] for h in hits])\n",
    "\n",
    "\n",
    "hits = [i for i in _mongo_coll_8.find({'_hit_comment':'robert new 1'})]\n",
    "hits = [i for i in _mongo_coll_8.find({'_hit_id':10})]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This is processAssignments modified to read in from mongodb rather than mturk.\n",
    "# Run it in a python terminal on the server.\n",
    "\n",
    "from mturk_api import mturk_depth_api_lsp as m\n",
    "\n",
    "def processAssignments( save = True, savePath = '/home/ubuntu/amt_guis/cocoa_depth/hits/lsp/', hit_name = '', verbose = False ):\n",
    "    hits = [i for i in _mongo_coll_8.find()]\n",
    "    for h in hits:\n",
    "        if h['_worker_id'] == 'A1GM8ZHDSD19ZQ':\n",
    "            h['_worker_id'] = 'ADU86DR9LRC0G'\n",
    "    \n",
    "    assignments_data = hits\n",
    "    \n",
    "    #_mtc = MTurkConnection( host = _host )\n",
    "    #mtc_assignments = getReviewableAssignments()\n",
    "    #assignments_data = extractAssignmentData( mtc_assignments, verbose )\n",
    "    \n",
    "    # Simple filter for only the assignments\n",
    "    new_assignments_data = []\n",
    "    for ass_data in assignments_data:\n",
    "         _trials_results_dict = json.loads( ass_data['_trials_results'] )\n",
    "         # print _trials_results_dict[_trials_results_dict.keys()[0]].keys()\n",
    "         if \"_lsp_subj_id\" not in _trials_results_dict[_trials_results_dict.keys()[0]].keys():\n",
    "             continue\n",
    "            \n",
    "         new_assignments_data.append(ass_data)\n",
    "        \n",
    "    assignments_data = new_assignments_data\n",
    "    \n",
    "    num_assignments = len(assignments_data)\n",
    "    \n",
    "    # store assignments info here, for persistence\n",
    "    # list containing all the assignments\n",
    "    _all_assignments = []\n",
    "    # list containing the assignments that were flagged by the turkers\n",
    "    _flagged_assignments = []\n",
    "    # list with the assignments that were rejected\n",
    "    _rejected_assignments = []\n",
    "    # list with the assignments that are not rejected nor flagged\n",
    "    _good_assignments = []\n",
    "    # list with the assignments were something inexpected on my side happened\n",
    "    _error_assignments = []\n",
    "    \n",
    "    worker_ids = set()\n",
    "    \n",
    "    print \"====================================================\"\n",
    "    print \"Number of Assignments to analyze: [%d]\" %(num_assignments)\n",
    "    print \"====================================================\"\n",
    "    \n",
    "    count = 0\n",
    "    for ass_data in assignments_data:\n",
    "        count += 1\n",
    "        if verbose:\n",
    "            print \" - Assignment [%d/%d]\" %(count,num_assigments)\n",
    "        \n",
    "        worker_ids.add( ass_data['_worker_id'] )\n",
    "        \n",
    "        cleaned_data     = m.cleanAssignmentData( ass_data )\n",
    "        _polished_data   = cleaned_data[0]\n",
    "        _error           = cleaned_data[1]\n",
    "        _hit_reject_flag = cleaned_data[2]\n",
    "        _hit_flag        = cleaned_data[3]\n",
    "        \n",
    "        _all_assignments.append( _polished_data )\n",
    "        if _error:\n",
    "            _error_assignments.append( _polished_data )\n",
    "        else:\n",
    "            if _hit_reject_flag:\n",
    "                _rejected_assignments.append( _polished_data )\n",
    "            else:\n",
    "                if _hit_flag:\n",
    "                    _flagged_assignments.append( _polished_data )\n",
    "                else:\n",
    "                    _good_assignments.append( _polished_data )\n",
    "    \n",
    "    # print out some stats\n",
    "    print \"Distinct workers:               [%d]\" % (len(worker_ids),)\n",
    "    print \"Total number of assignments:    [%d]\" % (len(_all_assignments),)\n",
    "    print \"Rejected assignments:           [%d]\" % (len(_rejected_assignments),)\n",
    "    print \"Flagged assignments:            [%d]\" % (len(_flagged_assignments),)\n",
    "    print \"Good assignments:               [%d]\" % (len(_good_assignments),)\n",
    "    print \"Error assignments:              [%d]\" % (len(_error_assignments),)\n",
    "    \n",
    "    return_dict = {\n",
    "        \"_all_assignments\":_all_assignments,\n",
    "        \"_rejected_assignments\":_rejected_assignments,\n",
    "        \"_flagged_assignments\":_flagged_assignments,\n",
    "        \"_good_assignments\":_good_assignments,\n",
    "        \"_error_assignments\":_error_assignments}\n",
    "    \n",
    "    if save:\n",
    "        if savePath == '':\n",
    "            if 'MTURK_STORAGE_PATH' in os.environ:\n",
    "                savePath = os.environ['MTURK_STORAGE_PATH']\n",
    "            else:\n",
    "                savePath == './'\n",
    "        \n",
    "        if hit_name == '':\n",
    "            hit_name = 'cocoa_test_completed_' + str(len(_all_assignments)) + '_DepthHITS'\n",
    "        \n",
    "        time_stamp = time.strftime( \"%Y-%m-%d_%H-%M-%S\" )\n",
    "        \n",
    "        filename = os.path.join( savePath, hit_name + '_' + time_stamp + \".pkl\")\n",
    "        \n",
    "        print \"Storing created hit data at %s\" % (filename)\n",
    "        with open(filename, 'wb') as f:\n",
    "            pickle.dump( return_dict, f )\n",
    "            \n",
    "    return return_dict\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import pickle\n",
    "processAssignments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# These are the missing hit ids for matteo and me.\n",
    "matteo\n",
    "2, 12, 19, 20\n",
    "\n",
    "reng\n",
    "5, 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_mongo_coll_1.insert({u'_keypoints_bbox': [0, 0, 256, 256], u'_image_keypoints': [110, 21, 2, 137, 43, 2, 86, 58, 2, 151, 39, 2, 89, 94, 2, 146, 45, 2, 114, 88, 2, 127, 117, 2, 87, 118, 2, 169, 163, 2, 119, 162, 2, 142, 214, 2, 114, 219, 2], u'_comps': [[0, 2], [6, 11], [5, 6], [2, 3], [5, 8]], u'_lsp_img_src': u'/static/images/human/human36m_train_0000279782.jpg', u'_lsp_subj_id': 279782, u'_lsp_img_id': 279782})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "LSP_RAW_RESULT_PATH = \"/Users/Robert/Downloads/LSP_FINALIZED_HITS_2018-04-27_17-33-24.pkl\"\n",
    "data = pickle.load(open(LSP_RAW_RESULT_PATH, 'r'))\n",
    "data = data['_good_assignments'] + data['_flagged_assignments']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "subj_id_to_comps = {}\n",
    "\n",
    "for d in data:\n",
    "    for t in d['trials']:\n",
    "        subj_id_to_comps[t['lsp_subj_id']] = [[int(c) for c in comp.split(',')] for comp in t['depth']['keypoint_comparisons_res'].keys()]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for subj_id, comps in subj_id_to_comps.iteritems():\n",
    "    if len(comps) < 5:\n",
    "        print subj_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[item for item in _mongo_coll_1.find({'_lsp_img_id':1900})]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[9, 10], [2, 10], [1, 4], [9, 13], [0, 3]]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subj_id_to_comps[1180]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
